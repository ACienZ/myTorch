{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语言模型（输入一个句子，输出这个句子产生的概率）\n",
    "\n",
    "学习目标\n",
    "- 学习语言模型，以及如何训练一个语言模型\n",
    "- 学习torchtext的基本使用方法\n",
    "    - 构建 vocabulary\n",
    "    - word to inde 和 index to word\n",
    "- 学习torch.nn的一些基本模型\n",
    "    - Linear\n",
    "    - RNN\n",
    "    - LSTM\n",
    "    - GRU\n",
    "- RNN的训练技巧\n",
    "    - Gradient Clipping\n",
    "- 如何保存和读取模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用工程需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'deviceevice'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-8c50a151c012>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeviceevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'cuda'\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m'cpu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#固定random seed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'deviceevice'"
     ]
    }
   ],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "USE_CUDA=torch.cuda.is_available()\n",
    "device=torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "#固定random seed\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "if USE_CUDA:\n",
    "    torch.cudada.manual_seed(1)\n",
    "    \n",
    "#一个bantch中有多少个句子\n",
    "BATCH_SIZE=32 \n",
    "#word embedding 的维度\n",
    "EMBEDDING_SIZE=650\n",
    "MAX_BOCAB_SIZE=50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建vocabulary(单词表)\n",
    "- 安装[torchtext](https://github.com/pytorch/text)  (用于文本预处理)  \n",
    "    pip install torchtext  \n",
    "- 使用 torchtext 来创建vocabulary, 然后把数据读成batch的格式。请大家自行阅读README来学习torchtext。  \n",
    "- **注意变更**：  \n",
    "    torchtext.data.Field -> torchtext.legacy.data.Field  \n",
    "    torchtext.datasets.LanguageModelingDataset -> torchtext.legacy.datasets.LanguageModelingDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用field预处理数据；利用LanguageMOdelingDataset class创建三个dataset\n",
    "继续使用text8数据集作为训练、验证和测试数据\n",
    "1. TorchText的一个重要概念是[Field](https://torchtext.readthedocs.io/en/latest/data.html#field)，其决定了数据会被如何处理  \n",
    "    我们使用TEXT这个field来处理文本数据  \n",
    "    我们的TEXT field有lower-Ture这个参数，故所有的单词都会被lowercase  \n",
    "    torchtext提供了LanguageModelingDataset这个class来帮助处理语言模型数据集  \n",
    "2. build_vocab可以根据我们提供的训练数据集来创建最高频单词的单词表，max_size帮助我们限定单词总量\n",
    "3. BPTTIterator可以连续地获得连贯的句子，[BPTT](https://zh.d2l.ai/chapter_recurrent-neural-networks/bptt.html): back propagation through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#确定数据集路径\n",
    "script_path=os.path.abspath('__file__')\n",
    "dir_path=os.path.dirname(script_path)\n",
    "path=os.path.join(dir_path,'text8')\n",
    "print(path,type(path))\n",
    "\n",
    "#创建一个名为TEXT的Field\n",
    "#lower=True: 将所有单词lowercase\n",
    "TEXT=torchtext.legacy.data.Field(lower=True)\n",
    "#创建用于language modeling的train, val, test三个dataset\n",
    "train, val, test = torchtext.legacy.datasets.LanguageModelingDataset.splits(path=path, \n",
    "                                                                            train='text8.train.txt', \n",
    "                                                                            validation='text8.dev.txt', \n",
    "                                                                            test='text8.test.txt', \n",
    "                                                                            text_field=TEXT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建Vocabulary\n",
    "- 创建vocabulary(单词表)相当于__myTorch/2/wordEmbeddingNotebook/2.ipynb#数据预处理及相关操作__中创建vocab参数的过程\n",
    "- 具体流程是从dataset中取出出现频数最高的前MAX_BOCAB_SIZE个单词作为Vocabulary\n",
    "- 单词表单词个数为50002个而不是50000个，是因为TorchText为我们增加了两个特殊的token：  \n",
    "    \\< unk \\>: 表示未知的，不在单词表中的单词  \n",
    "    \\< pad \\>: 表示padding，当句子较短时，将\\< pad \\>添加进句子末尾补齐长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建training dataset的vocabulary 单词数量为MAX_BOCAB_SIZE\n",
    "TEXT.build_vocab(train, max_size=MAX_BOCAB_SIZE)\n",
    "#注意单词个数是50002个，而不是MAX_BOCAB_SIZE指定的50000个\n",
    "print(len(TEXT.vocab)) #vocabulary size\n",
    "\n",
    "#itos: index to string\n",
    "print(type(TEXT.vocab.itos))\n",
    "print(TEXT.vocab.itos[:10]) #注意<unk>和<pad>\n",
    "\n",
    "#stoi: string to index\n",
    "print(type(TEXT.vocab.stoi))\n",
    "print(TEXT.vocab.stoi['apple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建batch(iterator)\n",
    "为dataset创建batch，每个batch包含BATCH_SIZE个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bptt_len:  Length of sequences for backpropagation through time.\n",
    "#具体参考：https://zh.d2l.ai/chapter_recurrent-neural-networks/bptt.html\n",
    "#repeat=False: 过完一边dataset后就结束一次epoch\n",
    "train_iter, val_iter, test_iter=torchtext.data.BPTTIterator.splits(\n",
    "    (train, val, test), \n",
    "    batch_sizes=BATCH_SIZE, \n",
    "    device=device, \n",
    "    bptt_len=25, \n",
    "    repeat=False, \n",
    "    suhuffle=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#测试\n",
    "it=iter(train_iter)\n",
    "batch=next(it)\n",
    "print(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
