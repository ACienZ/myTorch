{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 语言模型（输入一个句子，输出这个句子产生的概率）\n",
    "\n",
    "目标：根据之前的单词预测下一个单词。\n",
    "\n",
    "\n",
    "学习目标\n",
    "- 学习语言模型，以及如何训练一个语言模型\n",
    "- 学习torchtext的基本使用方法\n",
    "    - 构建 vocabulary\n",
    "    - word to inde 和 index to word\n",
    "- 学习torch.nn的一些基本模型\n",
    "    - Linear\n",
    "    - RNN\n",
    "    - LSTM\n",
    "    - GRU\n",
    "- RNN的训练技巧\n",
    "    - Gradient Clipping\n",
    "- 如何保存和读取模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调用工程需要的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "USE_CUDA=torch.cuda.is_available()\n",
    "device=torch.device('cuda' if USE_CUDA else 'cpu')\n",
    "\n",
    "#固定random seed\n",
    "random.seed(1)\n",
    "np.random.seed(1)\n",
    "torch.manual_seed(1)\n",
    "if USE_CUDA:\n",
    "    torch.cudada.manual_seed(1)\n",
    "    \n",
    "#一个bantch中有多少个句子\n",
    "BATCH_SIZE=32 \n",
    "#word embedding 的维度\n",
    "EMBEDDING_SIZE=650\n",
    "MAX_VOCAB_SIZE=50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建vocabulary(单词表)\n",
    "- 安装[torchtext](https://github.com/pytorch/text)  (用于文本预处理)  \n",
    "    pip install torchtext  \n",
    "- 使用 torchtext 来创建vocabulary, 然后把数据读成batch的格式。请大家自行阅读README来学习torchtext。  \n",
    "- **注意变更**：  \n",
    "    torchtext.data.Field -> torchtext.legacy.data.Field  \n",
    "    torchtext.datasets.LanguageModelingDataset -> torchtext.legacy.datasets.LanguageModelingDataset  \n",
    "    torchtext.data.BPTTIterator -> torchtext.legacy.data.BPTTIterator  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用field预处理数据；利用LanguageMOdelingDataset class创建三个dataset\n",
    "继续使用text8数据集作为训练、验证和测试数据\n",
    "1. TorchText的一个重要概念是[Field](https://torchtext.readthedocs.io/en/latest/data.html#field)，其决定了数据会被如何处理  \n",
    "    我们使用TEXT这个field来处理文本数据  \n",
    "    我们的TEXT field有lower-Ture这个参数，故所有的单词都会被lowercase  \n",
    "    torchtext提供了LanguageModelingDataset这个class来帮助处理语言模型数据集  \n",
    "2. build_vocab可以根据我们提供的训练数据集来创建最高频单词的单词表，max_size帮助我们限定单词总量\n",
    "3. BPTTIterator可以连续地获得连贯的句子，[BPTT](https://zh.d2l.ai/chapter_recurrent-neural-networks/bptt.html): back propagation through time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Re_AC\\Desktop\\Pytorch\\myTorch\\3\\languageModelNoteBook\\text8 <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "#确定数据集路径\n",
    "script_path=os.path.abspath('__file__')\n",
    "dir_path=os.path.dirname(script_path)\n",
    "path=os.path.join(dir_path,'text8')\n",
    "print(path,type(path))\n",
    "\n",
    "#创建一个名为TEXT的Field\n",
    "#lower=True: 将所有单词lowercase\n",
    "TEXT=torchtext.legacy.data.Field(lower=True)\n",
    "#创建用于language modeling的train, val, test三个dataset\n",
    "#将data split\n",
    "train, val, test = torchtext.legacy.datasets.LanguageModelingDataset.splits(path=path, \n",
    "                                                                            train='text8.train.txt', \n",
    "                                                                            validation='text8.dev.txt', \n",
    "                                                                            test='text8.test.txt', \n",
    "                                                                            text_field=TEXT)\n",
    "# print(train)\n",
    "# print(dir(train))\n",
    "# print(train.examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建Vocabulary\n",
    "- 创建vocabulary(单词表)相当于__myTorch/2/wordEmbeddingNotebook/2.ipynb#数据预处理及相关操作__中创建vocab参数的过程\n",
    "- 具体流程是从dataset中取出出现频数最高的前MAX_BOCAB_SIZE个单词作为Vocabulary\n",
    "- 单词表单词个数为50002个而不是50000个，是因为TorchText为我们增加了两个特殊的token：  \n",
    "    \\< unk \\>: 表示未知的，不在单词表中的单词  \n",
    "    \\< pad \\>: 表示padding，当句子较短时，将\\< pad \\>添加进句子末尾补齐长度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50002\n",
      "<class 'list'>\n",
      "['<unk>', '<pad>', 'the', 'of', 'and', 'one', 'in', 'a', 'to', 'zero']\n",
      "<class 'collections.defaultdict'>\n",
      "1259\n"
     ]
    }
   ],
   "source": [
    "#创建training dataset的vocabulary 单词数量为MAX_BOCAB_SIZE\n",
    "TEXT.build_vocab(train, max_size=MAX_BOCAB_SIZE)\n",
    "#注意单词个数是50002个，而不是MAX_BOCAB_SIZE指定的50000个\n",
    "\n",
    "VOCAB_SIZE = len(TEXT.vocab)\n",
    "print(len(TEXT.vocab)) #vocabulary size\n",
    "\n",
    "#itos: index to string\n",
    "print(type(TEXT.vocab.itos))\n",
    "print(TEXT.vocab.itos[:10]) #注意<unk>和<pad>\n",
    "\n",
    "#stoi: string to index\n",
    "print(type(TEXT.vocab.stoi))\n",
    "print(TEXT.vocab.stoi['apple'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建batch(iterator)\n",
    "为dataset创建batch，每个batch包含BATCH_SIZE个句子"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bptt_len:  Length of sequences for backpropagation through time.\n",
    "#此处也决定了batch中每个句子的长度\n",
    "#具体参考：https://zh.d2l.ai/chapter_recurrent-neural-networks/bptt.html\n",
    "#repeat=False: 过完一边dataset后就结束一次epoch\n",
    "train_iter, val_iter, test_iter=torchtext.legacy.data.BPTTIterator.splits(\n",
    "    (train, val, test), \n",
    "    batch_size=BATCH_SIZE, \n",
    "    device=device, \n",
    "    bptt_len=50, \n",
    "    repeat=False, \n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.legacy.data.batch.Batch of size 32]\n",
      "\t[.text]:[torch.LongTensor of size 50x32]\n",
      "\t[.target]:[torch.LongTensor of size 50x32]\n",
      "tensor([[ 5269,  6271,   417,  ...,  5931,     3, 24395],\n",
      "        [ 3110,     6,   288,  ...,    57,   168,     6],\n",
      "        [   13,  3593,   458,  ...,    12, 27121,   314],\n",
      "        ...,\n",
      "        [    8,  1576,     3,  ...,    98,     4,     8],\n",
      "        [ 3661,     2,   173,  ...,    33,     6,  6264],\n",
      "        [    2,  2694,  1284,  ...,   479,  2526,    68]])\n",
      "anarchism originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the\n",
      "\n",
      "originated as a term of abuse first used against early working class radicals including the diggers of the english revolution and the sans <unk> of the french revolution whilst the term is still used in a pejorative way to describe any act that used violent means to destroy the organization\n"
     ]
    }
   ],
   "source": [
    "#测试+加深理解\n",
    "it=iter(train_iter)\n",
    "batch=next(it)\n",
    "print(batch)\n",
    "#50: 句子长度(=bptt_len)  32: batch_size\n",
    "# [torchtext.legacy.data.batch.Batch of size 32]\n",
    "# \t[.text]:[torch.LongTensor of size 50x32]\n",
    "# \t[.target]:[torch.LongTensor of size 50x32]\n",
    "\n",
    "#可以看到text为文件：text8.train.txt的内容\n",
    "#target与text相似，但从text中的下一个单词开始，比text多一个单词结束\n",
    "#输入dataset中的一个单词，target（输出）为dataset中的下一个单词\n",
    "#模型的目的是预测下一个单词是什么\n",
    "print(batch.text)\n",
    "print(' '.join(TEXT.vocab.itos[i] for i in batch.text[:,0].data))\n",
    "print()\n",
    "print(' '.join(TEXT.vocab.itos[i] for i in batch.target[:,0].data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0\n",
      "organization of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing\n",
      "\n",
      "of society it has also been taken up as a positive label by self defined anarchists the word anarchism is derived from the greek without archons ruler chief king anarchism as a political philosophy is the belief that rulers are unnecessary and should be abolished although there are differing interpretations\n",
      "\n",
      "1\n",
      "interpretations of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or <unk> but rather a harmonious anti authoritarian society in place of what are regarded\n",
      "\n",
      "of what this means anarchism also refers to related social movements that advocate the elimination of authoritarian institutions particularly the state the word anarchy as most anarchists use it does not imply chaos nihilism or <unk> but rather a harmonious anti authoritarian society in place of what are regarded as\n",
      "\n",
      "2\n",
      "as authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society\n",
      "\n",
      "authoritarian political structures and coercive economic institutions anarchists advocate social relations based upon voluntary association of autonomous individuals mutual aid and self governance while anarchism is most easily defined by what it is against anarchists also offer positive visions of what they believe to be a truly free society however\n",
      "\n",
      "3\n",
      "however ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow\n",
      "\n",
      "ideas about how an anarchist society might work vary considerably especially with respect to economics there is also disagreement about how a free society might be brought about origins and predecessors kropotkin and others argue that before recorded history human society was organized on anarchist principles most anthropologists follow kropotkin\n",
      "\n",
      "4\n",
      "kropotkin and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in\n",
      "\n",
      "and engels in believing that hunter gatherer bands were egalitarian and lacked division of labour accumulated wealth or decreed law and had equal access to resources william godwin anarchists including the the anarchy organisation and rothbard find anarchist attitudes in taoism from ancient china kropotkin found similar ideas in stoic\n"
     ]
    }
   ],
   "source": [
    "#多拿几个train_iter中的batch，看看text和target中的内容\n",
    "for i in range(5):\n",
    "    batch=next(it)\n",
    "    print()\n",
    "    print(i)\n",
    "    print(' '.join(TEXT.vocab.itos[i] for i in batch.text[:,0].data))\n",
    "    print()\n",
    "    print(' '.join(TEXT.vocab.itos[i] for i in batch.target[:,0].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型（简单的）\n",
    "- 继承nn.Module\n",
    "- \\_\\_init\\_\\_函数\n",
    "- forward函数\n",
    "- 其余可以根据模型需要定义相关函数  \n",
    "\n",
    "\n",
    "**PyTorch处理RNN时默认第一个维度为sequence length，第二个维度为batch_size**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "#定义一个简单的RNN （一层）\n",
    "class RNNModel(nn.Module):\n",
    "    #定义需要参数\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        #embedding层\n",
    "        self.embed=nn.Embedding(vocab_size, embed_size) # W大小：(50002, 650) \n",
    "        #LSTM层\n",
    "        self.lstm=nn.LSTM(embed_size, hidden_size)\n",
    "        # batch_first=True: 将lstm第一个维度改为batch_size\n",
    "        # self.lstm=nn.LSTM(embed_size, hidden_size, batch_first=True)\n",
    "        # 将LSTM的结果decode为一个vocab_size维的向量，以确定预测的单词\n",
    "        self.decoder=nn.Linear(hidden_size, vocab_size)\n",
    "    \n",
    "    #定义网络架构\n",
    "    def forward(self, input_text, hidden):\n",
    "        #forward pass\n",
    "        #input_text: seq_length(50) * batch_size(32)\n",
    "        emb= self.embed(input_text) # seq_length * batch_size * embed_size\n",
    "        #embedding传入LSTM\n",
    "        output, hidden = self.lstm(emb, hidden)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
