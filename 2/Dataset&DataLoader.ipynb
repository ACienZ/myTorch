{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**https://blog.csdn.net/qq_36653505/article/details/83351808**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取数据 预处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.两者区别\n",
    "\n",
    "### torch.utils.data.Dataset\n",
    "用于自定义数据集方法的抽象类\n",
    "可以自己定义数据类继承这个抽象类\n",
    "只需要定义__len__和__getitem__两个方法即可\n",
    "\n",
    "### torch.utils.data.DataLoader\n",
    "- 通过继承Dataset这个抽象类，我们可以定义需要的数据类。但通过迭代的方式来取得每个数据，很难实现batch，shuffle，或者多线程读取数据\n",
    "可以通过torch.utils.data.DataLoader类来定义一个新的迭代器\n",
    "将自定义的数据读取接口的输出/PyTorch已有的数据读取接口的输入按照batch size封装成Tensor\n",
    "后续再包装成Bariable即可作为模型输入"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Dataset和DataLoader两个类中用到的魔法方法\n",
    "**\\_\\_len\\_\\_(self)**  **\\_\\_getitem\\_\\_(self)**  **\\_\\_iter\\_\\_(self)**  \n",
    "- \\_\\_len\\_\\_(self) 定义当被len()函数调用时的行为(返回容器中元素的个数)\n",
    "- \\_\\_getitem\\_\\_(self) 定义获取容器中指定元素的行为，相当于self[key],即允许类对象有索引操作\n",
    "- \\_\\_iter\\_\\_(self) 定义迭代容器中的元素时的行为"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1魔法方法 \\_\\_len\\_\\_() & \\_\\_getitem\\_\\_()的使用\n",
    "\\_\\_len\\_\\_() & \\_\\_getitem\\_\\_()可以用于定制容器类型数据(像序列类型（如列表、元组和字符串）或映射类型（如字典）都属于容器类型数据)\n",
    "- 如果容器不可变 只需要定义\\_\\_len\\_\\_()和\\_\\_getitem\\_\\_()这两个魔法方法\n",
    "- 如果容器可变 除了\\_\\_len\\_\\_()和\\_\\_getitem\\_\\_()这两个魔法方法，还需要定义\\_\\_setitem\\_\\_()和\\_\\_delitem\\_\\_()两个方法  \n",
    "\n",
    "e.g.: 编写一个不可变自定义列表，记录列表中每个元素被访问次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n",
      "11\n",
      "{0: 0, 1: 2, 2: 0, 3: 0, 4: 0}\n",
      "{0: 0, 1: 1, 2: 0, 3: 1, 4: 0}\n"
     ]
    }
   ],
   "source": [
    "class CountList:\n",
    "    def __init__(self, *args):\n",
    "        #存储列表具体值\n",
    "        self.values = [x for x in args]\n",
    "        #纪律列表中元素访问次数，初始值为0\n",
    "        #dict.fromkeys(seq,value)用于创建一个新字典，以序列seq中元素为新字典的键，value为字典键的初始值\n",
    "        self.count={}.fromkeys(range(len(self.values)),0)\n",
    "    #类被len()函数调用时的行为\n",
    "    def __len__(self):\n",
    "        return len(self.values)\n",
    "    #当类进行索引时进行的操作\n",
    "    def __getitem__(self, key):\n",
    "        self.count[key]+=1\n",
    "        return self.values[key]\n",
    "    \n",
    "#实例化类\n",
    "c1=CountList(1,3,5,7,9)\n",
    "c2=CountLIst(2,4,6,8,10)\n",
    "\n",
    "#调用\n",
    "print(c1[1])\n",
    "print(c2[1])\n",
    "print(c1[1]+c2[3])\n",
    "print(c1.count)\n",
    "print(c2.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2魔法方法__iter__()的使用\n",
    "在Python中构造迭代器时，需要定义\\_\\_iter\\_\\_()方法\n",
    "提供迭代方法的容器称为**迭代器**(序列(列表、元组、字符串)、字典)\n",
    "实现迭代器的魔法方法有两个：\n",
    "- \\_\\_iter\\_\\_()  \n",
    "这个方法实际上是返回迭代器本身\n",
    "- \\_\\_next\\_\\_()  \n",
    "该方法决定了迭代规则  \\\n",
    "\n",
    "e.g.: 定义斐波那契数列类，其实例每次顺序返回斐波那契数列的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "class Fibs:\n",
    "    def __init__(self, n=20):\n",
    "        self.a=0\n",
    "        self.b=1\n",
    "        self.n=n\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        self.a,self.b=self.b,self.a+self.b\n",
    "        if self.a>self.n:\n",
    "            raise StopIteration\n",
    "        return self.a\n",
    "\n",
    "#实例化\n",
    "fib=Fibs()\n",
    "\n",
    "#调用\n",
    "for i in fib:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Dataset类\n",
    "\n",
    "- 源码  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):  \n",
    "    \"\"\"An abstract class representing a Dataset.  \n",
    "\n",
    "    All other datasets should subclass it. All subclasses should override  \n",
    "    ``__len__``, that provides the size of the dataset, and ``__getitem__``,  \n",
    "    supporting integer indexing in range from 0 to len(self) exclusive.  \n",
    "    \"\"\"\n",
    "\n",
    "    def __getitem__(self, index):  \n",
    "        raise NotImplementedError  \n",
    "\n",
    "    def __len__(self):  \n",
    "        raise NotImplementedError  \n",
    "\n",
    "    def __add__(self, other):  \n",
    "        return ConcatDataset([self, other])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一个用来表示数据集的抽象类，其他所有的数据集都应该是这个类的子类，并且需要重写\\_\\_len\\_\\_和\\_\\_getitem\\_\\_。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.DataLoader类  \n",
    "- 源码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#源码无此参数 添加该参数是为了jupyter notebook运行时不报错\n",
    "default_collate=''\n",
    "\n",
    "class DataLoader(object):\n",
    "    r\"\"\"\n",
    "    Data loader. Combines a dataset and a sampler, and provides\n",
    "    single- or multi-process iterators over the dataset.\n",
    "\n",
    "    Arguments:\n",
    "        dataset (Dataset): dataset from which to load the data.\n",
    "        batch_size (int, optional): how many samples per batch to load\n",
    "            (default: 1).\n",
    "        shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
    "            at every epoch (default: False).\n",
    "        sampler (Sampler, optional): defines the strategy to draw samples from\n",
    "            the dataset. If specified, ``shuffle`` must be False.\n",
    "        batch_sampler (Sampler, optional): like sampler, but returns a batch of\n",
    "            indices at a time. Mutually exclusive with batch_size, shuffle,\n",
    "            sampler, and drop_last.\n",
    "        num_workers (int, optional): how many subprocesses to use for data\n",
    "            loading. 0 means that the data will be loaded in the main process.\n",
    "            (default: 0)\n",
    "        collate_fn (callable, optional): merges a list of samples to form a mini-batch.\n",
    "        pin_memory (bool, optional): If ``True``, the data loader will copy tensors\n",
    "            into CUDA pinned memory before returning them.\n",
    "        drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
    "            if the dataset size is not divisible by the batch size. If ``False`` and\n",
    "            the size of dataset is not divisible by the batch size, then the last batch\n",
    "            will be smaller. (default: False)\n",
    "        timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
    "            from workers. Should always be non-negative. (default: 0)\n",
    "        worker_init_fn (callable, optional): If not None, this will be called on each\n",
    "            worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
    "            input, after seeding and before data loading. (default: None)\n",
    "\n",
    "    .. note:: By default, each worker will have its PyTorch seed set to\n",
    "              ``base_seed + worker_id``, where ``base_seed`` is a long generated\n",
    "              by main process using its RNG. However, seeds for other libraies\n",
    "              may be duplicated upon initializing workers (w.g., NumPy), causing\n",
    "              each worker to return identical random numbers. (See\n",
    "              :ref:`dataloader-workers-random-seed` section in FAQ.) You may\n",
    "              use ``torch.initial_seed()`` to access the PyTorch seed for each\n",
    "              worker in :attr:`worker_init_fn`, and use it to set other seeds\n",
    "              before data loading.\n",
    "\n",
    "    .. warning:: If ``spawn`` start method is used, :attr:`worker_init_fn` cannot be an\n",
    "                 unpicklable object, e.g., a lambda function.\n",
    "    \"\"\"\n",
    "\n",
    "    __initialized = False\n",
    "\n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False, sampler=None, batch_sampler=None,\n",
    "                 num_workers=0, collate_fn=default_collate, pin_memory=False, drop_last=False,\n",
    "                 timeout=0, worker_init_fn=None):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.collate_fn = collate_fn\n",
    "        self.pin_memory = pin_memory\n",
    "        self.drop_last = drop_last\n",
    "        self.timeout = timeout\n",
    "        self.worker_init_fn = worker_init_fn\n",
    "\n",
    "        if timeout < 0:\n",
    "            raise ValueError('timeout option should be non-negative')\n",
    "\n",
    "        if batch_sampler is not None:\n",
    "            if batch_size > 1 or shuffle or sampler is not None or drop_last:\n",
    "                raise ValueError('batch_sampler option is mutually exclusive '\n",
    "                                 'with batch_size, shuffle, sampler, and '\n",
    "                                 'drop_last')\n",
    "            self.batch_size = None\n",
    "            self.drop_last = None\n",
    "\n",
    "        if sampler is not None and shuffle:\n",
    "            raise ValueError('sampler option is mutually exclusive with '\n",
    "                             'shuffle')\n",
    "\n",
    "        if self.num_workers < 0:\n",
    "            raise ValueError('num_workers option cannot be negative; '\n",
    "                             'use num_workers=0 to disable multiprocessing.')\n",
    "\n",
    "        if batch_sampler is None:\n",
    "            if sampler is None:\n",
    "                if shuffle:\n",
    "                    sampler = RandomSampler(dataset)\n",
    "                else:\n",
    "                    sampler = SequentialSampler(dataset)\n",
    "            batch_sampler = BatchSampler(sampler, batch_size, drop_last)\n",
    "\n",
    "        self.sampler = sampler\n",
    "        self.batch_sampler = batch_sampler\n",
    "        self.__initialized = True\n",
    "\n",
    "    def __setattr__(self, attr, val):\n",
    "        if self.__initialized and attr in ('batch_size', 'sampler', 'drop_last'):\n",
    "            raise ValueError('{} attribute should not be set after {} is '\n",
    "                             'initialized'.format(attr, self.__class__.__name__))\n",
    "\n",
    "        super(DataLoader, self).__setattr__(attr, val)\n",
    "\n",
    "    def __iter__(self):\n",
    "        return _DataLoaderIter(self)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 DataLoader中的\\_\\_init\\_\\_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \\_\\_init\\_\\_()中的重要输入\n",
    "1. dataset  \n",
    "    PyTorch已有的数据读取接口(e.g.: torchvision.datasets.ImageFolder)或者自定义的数据接口的输出\n",
    "    该输出要么是torch.data.Dataset类的对象，要么是继承自torch.utils.data.Dataset类的自定义类的对象\n",
    "2. batch_size  \n",
    "    根据具体情况设置\n",
    "3. shuffle  \n",
    "    一般在训练数据中采用\n",
    "4. collate_fn  \n",
    "    用来处理不同情况下的输入dataset的封装，一般默认即可\n",
    "    除非自定义的数据读取输出非常少见\n",
    "5. batch_sampler  \n",
    "    和batch_size, shuffle等参数是互斥的，一般采用默认\n",
    "6. sampler  \n",
    "    与shuffle互斥，一般默认\n",
    "7. num_workers  \n",
    "    这个参数必须大于0，0表示数据导入在主进程中进行，大于0表示多个进程导入数据，可以加快数据导入速度\n",
    "8. pin_memory  \n",
    "    如果为True, dataloader将会在返回Tensors之前，将他们复制进[CUDA pinned memory](http://www.voidcn.com/article/p-fsdktdik-bry.html)\n",
    "9. timeout  \n",
    "    设置数据读取超时时间，超过这个时间还没读取到数据就会报错\n",
    "    \n",
    "\n",
    "### 在\\_\\_init\\_\\_中  \n",
    "- TandomSampler类表示随机采样且不重复，起到的就是shuffle的作用\n",
    "- BatchSampler类则把batch size个RandomSampler类对象封装成一个，这样就实现了随机选取一个batch的目的\n",
    "\n",
    "\n",
    "### 当取数据时  \n",
    "当要从DataLoader类生成的对象中取数据时，比如：  \n",
    "train_data=torch.utils.data.DataLoader(...)  \n",
    "for i, (input, target) in enumerate(train_data):  \n",
    "\n",
    "就会调用DataLoader类的__iter__方法，  其仅有一行代码：return DataLoaderIter(self)  \n",
    "因此需要对DataLoaderIter类进行分析  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 DataLoaderIter类\n",
    "\n",
    "- 源码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _DataLoaderIter(object):\n",
    "    r\"\"\"Iterates once over the DataLoader's dataset, as specified by the sampler\"\"\"\n",
    "\n",
    "    def __init__(self, loader):\n",
    "        self.dataset = loader.dataset\n",
    "        self.collate_fn = loader.collate_fn\n",
    "        self.batch_sampler = loader.batch_sampler\n",
    "        self.num_workers = loader.num_workers\n",
    "        self.pin_memory = loader.pin_memory and torch.cuda.is_available()\n",
    "        self.timeout = loader.timeout\n",
    "        self.done_event = threading.Event()\n",
    "\n",
    "        self.sample_iter = iter(self.batch_sampler)\n",
    "\n",
    "        base_seed = torch.LongTensor(1).random_().item()\n",
    "\n",
    "        if self.num_workers > 0:\n",
    "            self.worker_init_fn = loader.worker_init_fn\n",
    "            self.index_queues = [multiprocessing.Queue() for _ in range(self.num_workers)]\n",
    "            self.worker_queue_idx = 0\n",
    "            self.worker_result_queue = multiprocessing.SimpleQueue()\n",
    "            self.batches_outstanding = 0\n",
    "            self.worker_pids_set = False\n",
    "            self.shutdown = False\n",
    "            self.send_idx = 0\n",
    "            self.rcvd_idx = 0\n",
    "            self.reorder_dict = {}\n",
    "\n",
    "            self.workers = [\n",
    "                multiprocessing.Process(\n",
    "                    target=_worker_loop,\n",
    "                    args=(self.dataset, self.index_queues[i],\n",
    "                          self.worker_result_queue, self.collate_fn, base_seed + i,\n",
    "                          self.worker_init_fn, i))\n",
    "                for i in range(self.num_workers)]\n",
    "\n",
    "            if self.pin_memory or self.timeout > 0:\n",
    "                self.data_queue = queue.Queue()\n",
    "                if self.pin_memory:\n",
    "                    maybe_device_id = torch.cuda.current_device()\n",
    "                else:\n",
    "                    # do not initialize cuda context if not necessary\n",
    "                    maybe_device_id = None\n",
    "                self.worker_manager_thread = threading.Thread(\n",
    "                    target=_worker_manager_loop,\n",
    "                    args=(self.worker_result_queue, self.data_queue, self.done_event, self.pin_memory,\n",
    "                          maybe_device_id))\n",
    "                self.worker_manager_thread.daemon = True\n",
    "                self.worker_manager_thread.start()\n",
    "            else:\n",
    "                self.data_queue = self.worker_result_queue\n",
    "\n",
    "            for w in self.workers:\n",
    "                w.daemon = True  # ensure that the worker exits on process exit\n",
    "                w.start()\n",
    "\n",
    "            _update_worker_pids(id(self), tuple(w.pid for w in self.workers))\n",
    "            _set_SIGCHLD_handler()\n",
    "            self.worker_pids_set = True\n",
    "\n",
    "            # prime the prefetch loop\n",
    "            for _ in range(2 * self.num_workers):\n",
    "                self._put_indices()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.batch_sampler)\n",
    "\n",
    "    def _get_batch(self):\n",
    "        if self.timeout > 0:\n",
    "            try:\n",
    "                return self.data_queue.get(timeout=self.timeout)\n",
    "            except queue.Empty:\n",
    "                raise RuntimeError('DataLoader timed out after {} seconds'.format(self.timeout))\n",
    "        else:\n",
    "            return self.data_queue.get()\n",
    "\n",
    "    def __next__(self):\n",
    "        if self.num_workers == 0:  # same-process loading\n",
    "            indices = next(self.sample_iter)  # may raise StopIteration\n",
    "            batch = self.collate_fn([self.dataset[i] for i in indices])\n",
    "            if self.pin_memory:\n",
    "                batch = pin_memory_batch(batch)\n",
    "            return batch\n",
    "\n",
    "        # check if the next sample has already been generated\n",
    "        if self.rcvd_idx in self.reorder_dict:\n",
    "            batch = self.reorder_dict.pop(self.rcvd_idx)\n",
    "            return self._process_next_batch(batch)\n",
    "\n",
    "        if self.batches_outstanding == 0:\n",
    "            self._shutdown_workers()\n",
    "            raise StopIteration\n",
    "\n",
    "        while True:\n",
    "            assert (not self.shutdown and self.batches_outstanding > 0)\n",
    "            idx, batch = self._get_batch()\n",
    "            self.batches_outstanding -= 1\n",
    "            if idx != self.rcvd_idx:\n",
    "                # store out-of-order samples\n",
    "                self.reorder_dict[idx] = batch\n",
    "                continue\n",
    "            return self._process_next_batch(batch)\n",
    "\n",
    "    next = __next__  # Python 2 compatibility\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def _put_indices(self):\n",
    "        assert self.batches_outstanding < 2 * self.num_workers\n",
    "        indices = next(self.sample_iter, None)\n",
    "        if indices is None:\n",
    "            return\n",
    "        self.index_queues[self.worker_queue_idx].put((self.send_idx, indices))\n",
    "        self.worker_queue_idx = (self.worker_queue_idx + 1) % self.num_workers\n",
    "        self.batches_outstanding += 1\n",
    "        self.send_idx += 1\n",
    "\n",
    "    def _process_next_batch(self, batch):\n",
    "        self.rcvd_idx += 1\n",
    "        self._put_indices()\n",
    "        if isinstance(batch, ExceptionWrapper):\n",
    "            raise batch.exc_type(batch.exc_msg)\n",
    "        return batch\n",
    "\n",
    "    def __getstate__(self):\n",
    "        # TODO: add limited pickling support for sharing an iterator\n",
    "        # across multiple threads for HOGWILD.\n",
    "        # Probably the best way to do this is by moving the sample pushing\n",
    "        # to a separate thread and then just sharing the data queue\n",
    "        # but signalling the end is tricky without a non-blocking API\n",
    "        raise NotImplementedError(\"_DataLoaderIter cannot be pickled\")\n",
    "\n",
    "    def _shutdown_workers(self):\n",
    "        try:\n",
    "            if not self.shutdown:\n",
    "                self.shutdown = True\n",
    "                self.done_event.set()\n",
    "                for q in self.index_queues:\n",
    "                    q.put(None)\n",
    "                # if some workers are waiting to put, make place for them\n",
    "                try:\n",
    "                    while not self.worker_result_queue.empty():\n",
    "                        self.worker_result_queue.get()\n",
    "                except (FileNotFoundError, ImportError):\n",
    "                    # Many weird errors can happen here due to Python\n",
    "                    # shutting down. These are more like obscure Python bugs.\n",
    "                    # FileNotFoundError can happen when we rebuild the fd\n",
    "                    # fetched from the queue but the socket is already closed\n",
    "                    # from the worker side.\n",
    "                    # ImportError can happen when the unpickler loads the\n",
    "                    # resource from `get`.\n",
    "                    pass\n",
    "                # done_event should be sufficient to exit worker_manager_thread,\n",
    "                # but be safe here and put another None\n",
    "                self.worker_result_queue.put(None)\n",
    "        finally:\n",
    "            # removes pids no matter what\n",
    "            if self.worker_pids_set:\n",
    "                _remove_worker_pids(id(self))\n",
    "                self.worker_pids_set = False\n",
    "\n",
    "    def __del__(self):\n",
    "        if self.num_workers > 0:\n",
    "            self._shutdown_workers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**self.index_queue=multiprocessing.SimpleQueue()**  \n",
    "- multiprocessing时python中的多进程管理包  \n",
    "- threading时python中的多线程管理包  \n",
    "\n",
    "### 4.2.1DataLoaderIter类的\\_\\_init\\_\\_  \n",
    "- self.sample_iter=iter(self.batch_sampler)  \n",
    "    得到的self.sample_iter可以通过next(self.sample_iter)来获得batch size个数据的index  \n",
    "\n",
    "- self.rcvd_idx  \n",
    "    表示读取到的一个batch数据的index  \n",
    "    初始化为0  \n",
    "    该值在迭代读取数据的时候会用到  \n",
    "\n",
    "- if self.num_workers  \n",
    "    该语句针对多进程或单进程的情况进行初始化，若不是多进程读取数据，则不需要这些初始化操作  \n",
    "\n",
    "- 在if语句中通过multiprocessing.SimpleQueue()类创建了一个简单的队列对象  \n",
    "    multiprocessing.Process类就是构造进程的类  \n",
    "    此处根据设定的进程数来启动，然后赋值给self.workers  \n",
    "    接下来的一个for循环通过调用start方法一次启动self.workers中的进程  \n",
    "\n",
    "- self.pin_memory判断语句  \n",
    "    主要实现了多线程操作  \n",
    "\n",
    "- self.data_queue=queue.Queue()  \n",
    "    通过queue模块初始化得到一个先进先出的队列  \n",
    "    queue模块主要运用在多线程读取数据中  \n",
    "    \n",
    "- 在threading.Thread的args参数  \n",
    "    第一个参数in_data就是一个进程的数据  \n",
    "    一个进程中不同线程的数据也是通过队列来维护的，这里采用的是Python的queue模块来初始化得到一个队列：queue.Queue()。  \n",
    "    初始化结束后，就会调用__next__方法，接下来介绍。  \n",
    "    \n",
    "总的来说，如果设置为多进程读取数据，那么就会采用队列的方式来读，  \n",
    "如果不是采用多进程来读取数据，那就采用普通方式来读。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2DataLoaderIter类的\\_\\_next\\_\\_方法  \n",
    "\n",
    "- 第一个if语句  \n",
    "    用来处理self.num_workers等于0的情况，也就是不采用多进程进行数据读取  \n",
    "    可以看出在这个if语句中先通过indices = next(self.sample_iter)获取长度为batch size的列表：indices，  \n",
    "    这个列表的每个值表示一个batch中每个数据的index，每执行一次next操作都会读取一批长度为batch size的indices列表。  \n",
    "    然后通过self.collate_fn函数将batch size个tuple（每个tuple长度为2，其中第一个值是数据，Tensor类型，第二个值是标签，int类型）封装成一个list，  \n",
    "    这个list长度为2，两个值都是Tensor，一个是batch size个数据组成的FloatTensor，另一个是batch size个标签组成的LongTensor。  \n",
    "    所以简单讲self.collate_fn函数就是将batch size个分散的Tensor封装成一个Tensor。  \n",
    "    batch = pin_memory_batch(batch)中pin_memory_batch函数的作用就是将输入batch的每个Tensor都拷贝到CUDA中，该函数后面会详细介绍。  \n",
    "\n",
    "- 第二个if语句  \n",
    "    判断当前想要读取的batch的index(self.rcvd_idx)是否之前已经读出来过(已读出来的index和batch数据保存在self.reorder_dict字典中，  \n",
    "    可以结合最后的while语句一起看，因为self.reorder_dict字典的更新是在最后的while语句中），  \n",
    "    如果之前已经读取过了，就根据这个index从reorder_dict字典中弹出对应的数据。  \n",
    "    最后返回batch数据的时候是 return self._process_next_batch(batch)，该方法后面会详细介绍。主要做是获取下一个batch的数据index信息。 \n",
    "\n",
    "- 第三个if语句  \n",
    "    self.batches_outstanding的值在前面初始中调用self._put_indices()方法时修改了，  \n",
    "    所以假设你的进程数self.num_workers设置为3，那么这里self.batches_outstanding就是3*2=6，  \n",
    "    可具体看self._put_indices()方法。  \n",
    "\n",
    "- 最后的while循环  \n",
    "    真正用来从队列中读取数据的操作  \n",
    "    最主要的就是idx, batch = self._get_batch()  \n",
    "    通过调用_get_batch()方法来读取，后面有介绍  \n",
    "    简单讲就是调用了队列的get方法得到下一个batch的数据，得到的batch一般是长度为2的列表  \n",
    "    列表的两个值都是Tensor，分别表示数据（是一个batch的）和标签。  \n",
    "    _get_batch()方法除了返回batch数据外，还得到另一个输出：idx，这个输出表示batch的index，  \n",
    "    这个if idx != self.rcvd_idx条件语句表示如果你读取到的batch的index不等于当前想要的index:selg,rcvd_idx，  \n",
    "    那么就将读取到的数据保存在字典self.reorder_dict中：self.reorder_dict[idx] = batch，  \n",
    "    然后继续读取数据，直到读取到的数据的index等于self.rcvd_idx。  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3DataLoaderIter类的\\_get\\_batch方法  \n",
    "\n",
    "主要根据是否设置了超时时间来操作，如果超过指定的超时时间后没有从队列中读到数据就报错"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.4DataLoaderIter类的\\_process\\_next\\_batch方法  \n",
    "\n",
    "首先对self.rcvd_idx进行加一，也就是更新下下一个要读取的batch数据的index。然后调用_put_indices()方法获取下一个batch的每个数据的index。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.5DataLoaderIter类的\\_put\\_indices方法  \n",
    "\n",
    "该方法主要实现从self.sample_iter中读取下一个batch数据中每个数据的index：indices = next(self.sample_iter, None)，  \n",
    "注意这里的index和前面idx是不一样的，这里的index是一个batch中每个数据的index，idx是一个batch的index；  \n",
    "然后将读取到的index通过调用queue对象的put方法压到队列self.index_queue中：self.index_queue.put((self.send_idx, indices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_pytorch",
   "language": "python",
   "name": "venv_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
